{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3da07574",
   "metadata": {},
   "outputs": [],
   "source": [
    "#processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#dataset\n",
    "from sklearn import datasets\n",
    "\n",
    "#model selection\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "#pre-processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#visualization \n",
    "import seaborn as sns\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "\n",
    "#model\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#scoring\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "05b358db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
      "        1.189e-01],\n",
      "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
      "        8.902e-02],\n",
      "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
      "        8.758e-02],\n",
      "       ...,\n",
      "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
      "        7.820e-02],\n",
      "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
      "        1.240e-01],\n",
      "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
      "        7.039e-02]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
      "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
      "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
      "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
      "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
      "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
      "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
      "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
      "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), 'frame': None, 'target_names': array(['malignant', 'benign'], dtype='<U9'), 'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry\\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        worst/largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 0 is Mean Radius, field\\n        10 is Radius SE, field 20 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.', 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
      "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
      "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
      "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
      "       'smoothness error', 'compactness error', 'concavity error',\n",
      "       'concave points error', 'symmetry error',\n",
      "       'fractal dimension error', 'worst radius', 'worst texture',\n",
      "       'worst perimeter', 'worst area', 'worst smoothness',\n",
      "       'worst compactness', 'worst concavity', 'worst concave points',\n",
      "       'worst symmetry', 'worst fractal dimension'], dtype='<U23'), 'filename': 'breast_cancer.csv', 'data_module': 'sklearn.datasets.data'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "564    0\n",
       "565    0\n",
       "566    0\n",
       "567    0\n",
       "568    1\n",
       "Name: target, Length: 569, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = datasets.load_breast_cancer()\n",
    "\n",
    "print(data)\n",
    "\n",
    "df = pd.DataFrame(data=data.data, columns = data.feature_names)\n",
    "df['target'] = data.target\n",
    "\n",
    "df[\"target\"]\n",
    "\n",
    "\n",
    "#df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "818dbd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        mean radius  mean texture  mean perimeter     mean area  \\\n",
      "count  5.690000e+02  5.690000e+02    5.690000e+02  5.690000e+02   \n",
      "mean  -3.153111e-15 -6.568462e-15   -6.993039e-16 -8.553985e-16   \n",
      "std    1.000880e+00  1.000880e+00    1.000880e+00  1.000880e+00   \n",
      "min   -2.029648e+00 -2.229249e+00   -1.984504e+00 -1.454443e+00   \n",
      "25%   -6.893853e-01 -7.259631e-01   -6.919555e-01 -6.671955e-01   \n",
      "50%   -2.150816e-01 -1.046362e-01   -2.359800e-01 -2.951869e-01   \n",
      "75%    4.693926e-01  5.841756e-01    4.996769e-01  3.635073e-01   \n",
      "max    3.971288e+00  4.651889e+00    3.976130e+00  5.250529e+00   \n",
      "\n",
      "       mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
      "count     5.690000e+02      5.690000e+02    5.690000e+02         5.690000e+02   \n",
      "mean      6.081447e-15     -1.136369e-15   -2.997017e-16         1.023981e-15   \n",
      "std       1.000880e+00      1.000880e+00    1.000880e+00         1.000880e+00   \n",
      "min      -3.112085e+00     -1.610136e+00   -1.114873e+00        -1.261820e+00   \n",
      "25%      -7.109628e-01     -7.470860e-01   -7.437479e-01        -7.379438e-01   \n",
      "50%      -3.489108e-02     -2.219405e-01   -3.422399e-01        -3.977212e-01   \n",
      "75%       6.361990e-01      4.938569e-01    5.260619e-01         6.469351e-01   \n",
      "max       4.770911e+00      4.568425e+00    4.243589e+00         3.927930e+00   \n",
      "\n",
      "       mean symmetry  mean fractal dimension  ...  worst texture  \\\n",
      "count   5.690000e+02            5.690000e+02  ...   5.690000e+02   \n",
      "mean   -1.860648e-15           -1.504752e-15  ...   1.742016e-15   \n",
      "std     1.000880e+00            1.000880e+00  ...   1.000880e+00   \n",
      "min    -2.744117e+00           -1.819865e+00  ...  -2.223994e+00   \n",
      "25%    -7.032397e-01           -7.226392e-01  ...  -7.486293e-01   \n",
      "50%    -7.162650e-02           -1.782793e-01  ...  -4.351564e-02   \n",
      "75%     5.307792e-01            4.709834e-01  ...   6.583411e-01   \n",
      "max     4.484751e+00            4.910919e+00  ...   3.885905e+00   \n",
      "\n",
      "       worst perimeter    worst area  worst smoothness  worst compactness  \\\n",
      "count     5.690000e+02  5.690000e+02      5.690000e+02       5.690000e+02   \n",
      "mean     -1.198807e-15  6.118909e-16     -5.094929e-15      -2.122887e-15   \n",
      "std       1.000880e+00  1.000880e+00      1.000880e+00       1.000880e+00   \n",
      "min      -1.693361e+00 -1.222423e+00     -2.682695e+00      -1.443878e+00   \n",
      "25%      -6.895783e-01 -6.421359e-01     -6.912304e-01      -6.810833e-01   \n",
      "50%      -2.859802e-01 -3.411812e-01     -4.684277e-02      -2.695009e-01   \n",
      "75%       5.402790e-01  3.575891e-01      5.975448e-01       5.396688e-01   \n",
      "max       4.287337e+00  5.930172e+00      3.955374e+00       5.112877e+00   \n",
      "\n",
      "       worst concavity  worst concave points  worst symmetry  \\\n",
      "count     5.690000e+02          5.690000e+02    5.690000e+02   \n",
      "mean      6.118909e-16         -1.998011e-16   -2.422589e-15   \n",
      "std       1.000880e+00          1.000880e+00    1.000880e+00   \n",
      "min      -1.305831e+00         -1.745063e+00   -2.160960e+00   \n",
      "25%      -7.565142e-01         -7.563999e-01   -6.418637e-01   \n",
      "50%      -2.182321e-01         -2.234689e-01   -1.274095e-01   \n",
      "75%       5.311411e-01          7.125100e-01    4.501382e-01   \n",
      "max       4.700669e+00          2.685877e+00    6.046041e+00   \n",
      "\n",
      "       worst fractal dimension      target  \n",
      "count             5.690000e+02  569.000000  \n",
      "mean              2.497514e-15    0.627417  \n",
      "std               1.000880e+00    0.483918  \n",
      "min              -1.601839e+00    0.000000  \n",
      "25%              -6.919118e-01    0.000000  \n",
      "50%              -2.164441e-01    1.000000  \n",
      "75%               4.507624e-01    1.000000  \n",
      "max               6.846856e+00    1.000000  \n",
      "\n",
      "[8 rows x 31 columns]\n",
      "0.9605314009661836\n"
     ]
    }
   ],
   "source": [
    "#clean\n",
    "df.isnull().sum()\n",
    "\n",
    "\n",
    "#nomalize only the continuous variables\n",
    "df_standardized = pd.DataFrame(StandardScaler().fit_transform(df.drop('target', axis=1)))\n",
    "\n",
    "df_standardized['target'] = data.target\n",
    "df_standardized.columns = df.columns\n",
    "\n",
    "print(df_standardized.describe())\n",
    "\n",
    "\n",
    "df_standardized['target'].value_counts()\n",
    "\n",
    "\n",
    "#split into training and testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_standardized.iloc[:, :-1], df_standardized.iloc[:, -1], test_size=.2)\n",
    "\n",
    "\n",
    "\n",
    "#stratified cv\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "#create basline model to test against\n",
    "model = XGBClassifier()\n",
    "\n",
    "scores = cross_val_score(model, x_train, y_train, cv = cv, n_jobs=-1, scoring='accuracy')\n",
    "\n",
    "\n",
    "#print the basline score to improve upon\n",
    "print(mean(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6dd8e30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best results is 0.9714975845410627\n",
      "best paramaters are {'colsample_bytree': 0.3, 'max_depth': 15, 'n_estimators': 60, 'reg_lambda': 0}\n"
     ]
    }
   ],
   "source": [
    "#create lists of hyperparameters to fit and test\n",
    "#max_depth\n",
    "#colsample_bytree\n",
    "#n_estimators\n",
    "#reg_lambda\n",
    "\n",
    "param_grid = {'max_depth' :[5, 10, 15], \"colsample_bytree\":[.3, .5, .8], \"n_estimators\":[60, 80, 100, 120], \"reg_lambda\":[0, .5, 1]}\n",
    "\n",
    "\n",
    "grid_model = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, verbose=0, cv=cv)\n",
    "results = grid_model.fit(x_train, y_train)\n",
    "\n",
    "print(f\"best results is {results.best_score_}\")\n",
    "print(f\"best paramaters are {results.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "66022a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40  3]\n",
      " [ 2 69]]\n",
      "accuracy score:  0.956140350877193\n"
     ]
    }
   ],
   "source": [
    "#the accuracy of our model is improved\n",
    "\n",
    "test_results = grid_model.predict(x_test)\n",
    "\n",
    "print(confusion_matrix(y_test, test_results))\n",
    "print(\"accuracy score: \", accuracy_score(y_test, test_results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641a9184",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
